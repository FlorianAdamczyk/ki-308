{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 3. Regularisierte Regression: LASSO & Ridge\n",
    "\n",
    "**KI1-Projekt 308** — California Housing Datensatz\n",
    "\n",
    "**Schwerpunkt P1:** Feature-Selektion via LASSO, Ridge-Regression,\n",
    "polynomiale Feature-Transformation, Skalierungseffekte.\n",
    "\n",
    "Vorlage: HA9/10 Aufgabe 3 und HA11 Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from utils.data import load_and_clean_data, get_train_test_split\n",
    "from utils.evaluation import evaluate_model, add_result\n",
    "from utils.plotting import plot_predicted_vs_actual, plot_residuals, save_fig\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 3.1 Daten laden (ohne Skalierung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data()\n",
    "X_train, X_test, y_train, y_test, feature_names = get_train_test_split(df)\n",
    "print(f\"Features: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 3.2 LassoCV — Feature-Selektion ohne Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimales alpha: {lasso_cv.alpha_:.6f}\\n\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Koeffizient': lasso_cv.coef_\n",
    "})\n",
    "print(\"LASSO Koeffizienten:\")\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "selected_features = coef_df[coef_df['Koeffizient'] != 0]['Feature'].tolist()\n",
    "print(f\"\\nSelektierte Features ({len(selected_features)}/{len(feature_names)}): {selected_features}\")\n",
    "\n",
    "result_lasso = evaluate_model(lasso_cv, X_train, X_test, y_train, y_test, \"LassoCV (ohne Skalierung)\")\n",
    "add_result(result_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Auswertung: LassoCV ohne Skalierung\n",
    "\n",
    "Das optimale Regularisierungsparameter beträgt α = 0.010325. Bei diesem Wert setzt LASSO den Koeffizienten von **AveBedrms** exakt auf 0 und selektiert damit **7 von 8 Features**. Der stärkste positive Einfluss geht vom Medianeinkommen (`MedInc`, +0.386) aus, während geographische Lage (`Latitude`, –0.374; `Longitude`, –0.361) und Belegungsdichte (`AveOccup`, –0.344) stark negativ wirken. Dies ist plausibel: Küstennahe, einkommensstarke Gebiete haben deutlich höhere Hauspreise.\n",
    "\n",
    "| Metrik | Train | Test |\n",
    "|--------|-------|------|\n",
    "| R²     | 0.6358 | 0.6258 |\n",
    "| MAE    | 0.4325 | 0.4389 |\n",
    "| RMSE   | 0.5796 | 0.5831 |\n",
    "\n",
    "Der geringe Unterschied zwischen Train- und Test-R² (0.010) zeigt keine Overfitting-Tendenz. Allerdings erklärt das Modell nur ~63 % der Varianz — ein Hinweis, dass lineare Zusammenhänge ohne Skalierung und ohne nicht-lineare Terme unzureichend sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## 3.3 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=np.logspace(-3, 3, 100), cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimales alpha: {ridge_cv.alpha_:.6f}\\n\")\n",
    "\n",
    "result_ridge = evaluate_model(ridge_cv, X_train, X_test, y_train, y_test, \"RidgeCV (ohne Skalierung)\")\n",
    "add_result(result_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### Auswertung: RidgeCV ohne Skalierung\n",
    "\n",
    "Ridge wählt ein deutlich größeres α = 0.464159, da die L2-Strafe alle Koeffizienten gleichmäßig schrumpft, statt sie auf null zu setzen. Alle 8 Features bleiben im Modell erhalten.\n",
    "\n",
    "| Metrik | Train | Test |\n",
    "|--------|-------|------|\n",
    "| R²     | 0.6465 | 0.6326 |\n",
    "| MAE    | 0.4252 | 0.4341 |\n",
    "| RMSE   | 0.5710 | 0.5778 |\n",
    "\n",
    "**Vergleich LASSO vs. Ridge (ohne Skalierung):**\n",
    "- Ridge erzielt einen leicht höheren Test-R² (+0.007) und niedrigeren RMSE (–0.0053) gegenüber dem unskalerten LASSO.\n",
    "- Der Grund liegt darin, dass LASSO `AveBedrms` komplett herauswirft, obwohl dieser Feature nach Skalierung (s. Abschnitt 3.5) eine gewisse Erklärungskraft besitzt. Ohne Skalierung dominieren Features mit großen Zahlenwerten das L1-Kriterium.\n",
    "- **Fazit:** Ohne Skalierung ist Ridge dem LASSO leicht überlegen, weil es nicht durch unterschiedliche Feature-Skalen benachteiligt wird.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3.4 Mit MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mm, X_test_mm, y_train_mm, y_test_mm, scaler_mm, fn = get_train_test_split(df, scaler='minmax')\n",
    "\n",
    "lasso_cv_mm = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv_mm.fit(X_train_mm, y_train_mm)\n",
    "\n",
    "print(f\"Optimales alpha (MinMax): {lasso_cv_mm.alpha_:.6f}\")\n",
    "print(\"\\nKoeffizienten:\")\n",
    "for name, coef in zip(fn, lasso_cv_mm.coef_):\n",
    "    print(f\"  {name:15s}: {coef:.6f}\")\n",
    "\n",
    "result_lasso_mm = evaluate_model(lasso_cv_mm, X_train_mm, X_test_mm, y_train_mm, y_test_mm, \"LassoCV (MinMax)\")\n",
    "add_result(result_lasso_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### Auswertung: LassoCV mit MinMaxScaler\n",
    "\n",
    "Nach MinMax-Skalierung (alle Features auf [0, 1]) sinkt das optimale α drastisch auf 0.000078 — der Regularisierungsterm ist jetzt weit schwächer nötig, da alle Features vergleichbare Größenordnungen haben. Folglich werden **alle 8 Features beibehalten** (kein Koeffizient = 0).\n",
    "\n",
    "Die Koeffizienten sind nun direkt vergleichbar: `Longitude` (–3.679) und `Latitude` (–3.628) haben den stärksten Einfluss, gefolgt von `MedInc` (+5.542). `AveOccup` (–1.403) und `AveBedrms` (+1.255) sind ebenfalls relevant.\n",
    "\n",
    "| Metrik | Train | Test |\n",
    "|--------|-------|------|\n",
    "| R²     | 0.6465 | 0.6327 |\n",
    "| MAE    | 0.4252 | 0.4341 |\n",
    "| RMSE   | 0.5710 | 0.5778 |\n",
    "\n",
    "**Fazit:** Die Skalierung mit MinMax gleicht die Performance von LASSO an Ridge an — beide liefern nahezu identische Metriken. Das zeigt, dass LASSO ohne Skalierung systematisch schlechter abschneidet, weil es Features aufgrund ihrer Skalenunterschiede und nicht aufgrund ihrer Relevanz eliminiert.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## 3.5 Mit StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss, X_test_ss, y_train_ss, y_test_ss, scaler_ss, fn = get_train_test_split(df, scaler='standard')\n",
    "\n",
    "lasso_cv_ss = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv_ss.fit(X_train_ss, y_train_ss)\n",
    "\n",
    "print(f\"Optimales alpha (Standard): {lasso_cv_ss.alpha_:.6f}\")\n",
    "print(\"\\nKoeffizienten:\")\n",
    "for name, coef in zip(fn, lasso_cv_ss.coef_):\n",
    "    print(f\"  {name:15s}: {coef:.6f}\")\n",
    "\n",
    "result_lasso_ss = evaluate_model(lasso_cv_ss, X_train_ss, X_test_ss, y_train_ss, y_test_ss, \"LassoCV (Standard)\")\n",
    "add_result(result_lasso_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Auswertung: LassoCV mit StandardScaler\n",
    "\n",
    "Mit StandardScaler (Mittelwert 0, Standardabweichung 1) ergibt sich α = 0.000633 — ebenfalls sehr klein, da auch hier alle Features vergleichbar skaliert sind. Alle **8 Features bleiben erhalten**.\n",
    "\n",
    "Die normierten Koeffizienten zeigen: `MedInc` (+0.684) und die geographischen Features `Latitude` (–0.820) und `Longitude` (–0.739) haben den deutlichsten Einfluss. `AveOccup` (–0.225) wirkt als Belegungsdichte ebenfalls relevant.\n",
    "\n",
    "| Metrik | Train | Test |\n",
    "|--------|-------|------|\n",
    "| R²     | 0.6465 | 0.6327 |\n",
    "| MAE    | 0.4251 | 0.4340 |\n",
    "| RMSE   | 0.5710 | 0.5777 |\n",
    "\n",
    "**Vergleich MinMax vs. Standard:** Beide Skalierungen liefern quasi identische Metriken (Unterschied im Test-RMSE: 0.0001). Für LASSO ist die Wahl des Scalers bei linearen Modellen ohne Polynomtrans­formation nahezu irrelevant. StandardScaler ist jedoch für nachfolgende polynomiale Transformationen besser geeignet, da Ausreißer weniger Einfluss auf die Skalierung haben.\n",
    "\n",
    "**Fazit:** Skalierte LASSO-Modelle erreichen dieselbe Performance wie Ridge. Das deutet darauf hin, dass das lineare Modell mit diesen 8 Features ausgereizt ist und für weitere Verbesserungen nicht-lineare Erweiterungen nötig sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## 3.6 Polynomiale Feature-Transformation + LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomiale Features (Grad 2) auf skalierten Daten\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_ss)\n",
    "X_test_poly = poly.transform(X_test_ss)\n",
    "\n",
    "print(f\"Originale Features: {X_train_ss.shape[1]}\")\n",
    "print(f\"Polynomiale Features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "lasso_poly = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_poly.fit(X_train_poly, y_train_ss)\n",
    "\n",
    "result_lasso_poly = evaluate_model(\n",
    "    lasso_poly, X_train_poly, X_test_poly, y_train_ss, y_test_ss,\n",
    "    \"LassoCV (Poly Grad 2 + Standard)\"\n",
    ")\n",
    "add_result(result_lasso_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleichsplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "plot_predicted_vs_actual(\n",
    "    y_test_ss, lasso_cv_ss.predict(X_test_ss),\n",
    "    title=\"LassoCV (Standard)\", ax=axes[0]\n",
    ")\n",
    "plot_predicted_vs_actual(\n",
    "    y_test_ss, lasso_poly.predict(X_test_poly),\n",
    "    title=\"LassoCV (Poly+Standard)\", ax=axes[1]\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Vergleich: Linear vs. Polynomial\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "save_fig(fig, \"lasso_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Auswertung: LassoCV mit polynomialen Features (Grad 2)\n",
    "\n",
    "Durch die Erweiterung von 8 auf **44 Features** (alle Quadrat- und Kreuzterme) kann LASSO nicht-lineare Beziehungen und Interaktionen zwischen Features erfassen. Das optimale α wird erneut durch 5-fache Kreuzvalidierung bestimmt.\n",
    "\n",
    "| Metrik | Train | Test |\n",
    "|--------|-------|------|\n",
    "| R²     | 0.7028 | 0.6993 |\n",
    "| MAE    | 0.3770 | 0.3780 |\n",
    "| RMSE   | 0.5236 | 0.5228 |\n",
    "\n",
    "**Vergleich mit LassoCV (Standard) linear:**\n",
    "- R² (Test): +0.067 (+10,6 % relative Verbesserung)\n",
    "- MAE (Test): –0.056 (–12,8 %)\n",
    "- RMSE (Test): –0.055 (–9,5 %)\n",
    "\n",
    "Das Streudiagramm zeigt deutlich engere Punktewolken um die Ideallinie, besonders im mittleren Preissegment. Im oberen Preissegment (>3) bestehen weiterhin Unterschätzungstendenzen — ein Hinweis, dass die Preisverteilung nach oben durch den Datensatz möglicherweise gekappt ist.\n",
    "\n",
    "Der Train-Test-Unterschied bleibt minimal (R² Train–Test: 0.004), obwohl die Feature-Zahl von 8 auf 44 gestiegen ist. LASSO setzt dabei viele der 44 Features auf 0 und arbeitet effektiv als Feature-Selektion.\n",
    "\n",
    "**Fazit:** Polynomiale Erweiterung Grad 2 + LASSO bringt die stärkste Verbesserung aller getesteten Konfigurationen. Die Interaktionsterme (z. B. MedInc × Latitude) erfassen geografisch-einkommensbedingte Preisunterschiede, die lineare Modelle nicht abbilden können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### 3.Erweiterung auf Polynomialgrad 3\n",
    "\n",
    "Nach der deutlichen Leistungssteigerung durch polynomiale Features zweiten Grades stellt sich die Frage, ob eine weitere Erhöhung des Polynomgrades zusätzliche nicht-lineare Zusammenhänge erfassen kann. Theoretisch erlaubt ein Polynom dritten Grades die Modellierung komplexerer Interaktionen sowie kubischer Effekte einzelner Variablen.\n",
    "\n",
    "Gleichzeitig steigt mit zunehmendem Polynomgrad die Anzahl der generierten Features stark an (von 44 bei Grad 2 auf 164 bei Grad 3). Diese erhöhte Modellkomplexität kann zu Overfitting führen, da das Modell stärker an Trainingsdaten angepasst wird und die Generalisierungsfähigkeit sinken kann.\n",
    "\n",
    "Um dieses Risiko zu kontrollieren, wird die Erweiterung auf Grad 3 ausschließlich in Kombination mit L1-Regularisierung (LASSO) und 5-facher Kreuzvalidierung durchgeführt. Dadurch wird überprüft, ob zusätzliche Terme tatsächlich zur Verbesserung der Testperformance beitragen oder lediglich die Varianz des Modells erhöhen.\n",
    "\n",
    "Die Evaluation erfolgt analog zu den vorherigen Modellen anhand von R², MAE und RMSE auf Trainings- und Testdaten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Lösung mit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "pipe_poly3 = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "    (\"lasso\", LassoCV(cv=5, random_state=42, max_iter=20000))\n",
    "])\n",
    "\n",
    "pipe_poly3.fit(X_train, y_train)\n",
    "\n",
    "y_pred_poly3 = pipe_poly3.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## Feature-Anzahl Prüfen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly3 = pipe_poly3.named_steps[\"poly\"]\n",
    "print(\"Anzahl Features Grad 3:\", poly3.n_output_features_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Die Erweiterung auf Polynomgrad 3 erhöht die Anzahl der Features von 44 (Grad 2) auf 164(Grad3). Damit steigt die Modellkomplexität erheblich, da nun zusätzlich kubische Terme und Interaktionen höherer Ordnung berücksichtigt werden. Diese starke Erweiterung des Hypothesenraums erhöht potenziell die Modellflexibilität, birgt jedoch zugleich ein erhöhtes Overfitting-Risiko.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## Metriken vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "print(\"R2 Test:\", r2_score(y_test, y_pred_poly3))\n",
    "print(\"RMSE Test:\", np.sqrt(mean_squared_error(y_test, y_pred_poly3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Die Testperformance verbessert sich leicht gegenüber Grad 2. Das Test-R² steigt auf etwa 0.709, während der RMSE weiter sinkt. Die Verbesserung fällt jedoch moderat aus und liegt im Bereich von etwa einem Prozentpunkt R². Dies deutet darauf hin, dass zusätzliche kubische Terme nur begrenzt neue erklärende Information liefern.Im direkten Vergleich zeigt Grad 3 eine geringfügige Leistungssteigerung bei gleichzeitig stark erhöhter Feature-Anzahl. Der Zugewinn an Vorhersagegenauigkeit steht damit nicht im proportionalen Verhältnis zur gestiegenen Modellkomplexität. Die Verbesserung ist messbar, aber nicht substanziell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## Overfitting Prüfen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = pipe_poly3.predict(X_train)\n",
    "\n",
    "print(\"R2 Train:\", r2_score(y_train, y_train_pred))\n",
    "print(\"R2 Test:\", r2_score(y_test, y_pred_poly3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "Die Differenz zwischen Trainings- und Test-R² bleibt mit rund 0.009 sehr gering. Dies spricht gegen eine starke Overfitting-Tendenz. Trotz der hohen Feature-Dimension gelingt es der L1-Regularisierung, die Modellvarianz effektiv zu kontrollieren und eine stabile Generalisierung sicherzustellen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Cross-Validation-Stabilität prüfen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(pipe_poly3, X_train, y_train, cv=5, scoring=\"r2\")\n",
    "\n",
    "print(\"CV Mean:\", scores.mean())\n",
    "print(\"CV Std:\", scores.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Die Kreuzvalidierung zeigt eine konsistente Performance über mehrere Folds hinweg. Eine geringe Standardabweichung der R²-Werte deutet auf eine stabile Modellstruktur hin. Das Modell reagiert somit nicht übermäßig sensibel auf unterschiedliche Trainingssplits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "Die Erweiterung auf polynomiale Features dritten Grades führt zu einer leichten Verbesserung der Testperformance, ohne ausgeprägtes Overfitting zu verursachen. Gleichzeitig steigt die Anzahl der Features stark an, wodurch die Modellkomplexität erheblich zunimmt.\n",
    "\n",
    "Der zusätzliche Leistungsgewinn fällt jedoch vergleichsweise gering aus, was darauf hindeutet, dass der Großteil der relevanten Nichtlinearitäten bereits durch Grad 2 erfasst wurde.\n",
    "\n",
    "Insgesamt bestätigt das Experiment, dass höhere Modellkomplexität nicht zwangsläufig zu einer proportional besseren Generalisierung führt. Grad 3 bietet eine leichte Optimierung, während Grad 2 einen effizienteren Kompromiss zwischen Komplexität und Performance darstellt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "## 3.7 Zusammenfassung & Gesamtschlussfolgerung\n",
    "\n",
    "### Modellvergleich — Metriken (California Housing)\n",
    "\n",
    "| Modell | α | Features | R² Train | R² Test | MAE Test | RMSE Test |\n",
    "|--------|---|----------|----------|---------|----------|-----------|\n",
    "| LassoCV (ohne Skalierung) | 0.010325 | 7/8 | 0.6358 | 0.6258 | 0.4389 | 0.5831 |\n",
    "| RidgeCV (ohne Skalierung) | 0.464159 | 8/8 | 0.6465 | 0.6326 | 0.4341 | 0.5778 |\n",
    "| LassoCV (MinMax) | 0.000078 | 8/8 | 0.6465 | 0.6327 | 0.4341 | 0.5778 |\n",
    "| LassoCV (Standard) | 0.000633 | 8/8 | 0.6465 | 0.6327 | 0.4340 | 0.5777 |\n",
    "| **LassoCV (Poly Grad 2 + Standard)** | auto | **44→k** | **0.7028** | **0.6993** | **0.3780** | **0.5228** |\n",
    "| **LassoCV (Poly Grad 3 + Standard)** | auto | **164→k** | **0.7184** | **0.7091** | **0.7091** | **0.5142** |\n",
    "\n",
    "### Erkenntnisse im Überblick\n",
    "\n",
    "| Aspekt | Erkenntnis |\n",
    "|--------|-----------|\n",
    "| Feature-Selektion via LASSO | Ohne Skalierung eliminiert LASSO `AveBedrms` fälschlicherweise aufgrund von Skalenunterschieden |\n",
    "| Skalierung | Notwendig für LASSO, damit Feature-Wichtigkeit und nicht Feature-Skala bestraft wird |\n",
    "| Ridge vs. LASSO | Ridge behält ohne Skalierung alle Features und schlägt LASSO leicht; nach Skalierung sind beide gleichwertig |\n",
    "| Polynomiale Features (Grad 2) | Stärkste Verbesserung: R²(Test) +6,7 pp, RMSE –0.055 durch Interaktionsterme |\n",
    "| Overfitting | In allen Modellen minimal (Train-Test-Lücke ≤ 0.004 R²) — LASSO regularisiert effektiv |\n",
    "| Polynomiale Features (Grad 3)   | Leichte zusätzliche Verbesserung (R² ≈ 0.709), jedoch stark erhöhte Komplexität (164 Features) |\n",
    "| Overfitting                     | In allen Modellen minimal (Train-Test-Lücke ≤ 0.01 R²) – LASSO reguliert effektiv |\n",
    "\n",
    "\n",
    "\n",
    "### Gesamtschlussfolgerung\n",
    "\n",
    "Die Untersuchung zeigt, dass **Skalierung eine Voraussetzung** für den sinnvollen Einsatz von LASSO auf dem California-Housing-Datensatz ist: Ohne Skalierung werden Features durch Skalenunterschiede eliminiert, nicht durch mangelnde Relevanz. Nach korrekter Skalierung liefern LASSO (MinMax/Standard) und Ridge nahezu identische Ergebnisse (~R² = 0.633), was darauf hindeutet, dass das lineare Modell mit den gegebenen 8 Features an seine Grenzen stößt.\n",
    "\n",
    "Der entscheidende Qualitätssprung kommt durch **polynomiale Feature-Transformation (Grad 2)**: Das Erweitern des Featureraums auf 44 Terme erlaubt es LASSO, Interaktionen wie z. B. *MedInc × Latitude* zu nutzen, die nicht-lineare geographisch-einkommensbedingte Preiszusammenhänge abbilden. Das beste Modell (LassoCV Poly Grad 2 + Standard) erreicht R²(Test) = **0.699** und RMSE = **0.523** bei vernachlässigbarem Overfitting.\n",
    "\n",
    "Eine weitere Erweiterung auf polynomiale Features dritten Grades erhöht die Feature-Anzahl deutlich auf 164 und steigert damit die Modellkomplexität erheblich. Die Testperformance verbessert sich leicht auf R²(Test) ≈ 0.709 bei weiterhin geringer Train-Test-Differenz, sodass kein ausgeprägtes Overfitting erkennbar ist. Der zusätzliche Leistungsgewinn fällt jedoch moderat aus, was darauf hindeutet, dass der Großteil der relevanten Nichtlinearitäten bereits durch Grad 2 erfasst wird. Grad 3 liefert somit nur eine geringe Optimierung bei deutlich höherer Komplexität.\n",
    "\n",
    "Dennoch verbleiben ~30 % der Varianz unerklären. Für weitere Verbesserungen bieten sich an:\n",
    "- **Nicht-parametrische Methoden** (z. B. kNN, Entscheidungsbäume, Ensemble-Modelle)\n",
    "- **Neuronale Netze** (Ziel des Gesamtprojekts), die beliebig komplexe Nicht-Linearitäten approximieren können\n",
    "\n",
    "Im Kontext des Gesamtprojekts (Notebook 05_Neural_Network) bilden die hier dokumentierten LASSO/Ridge-Metriken (**RMSE ≈ 0.58 linear, 0.52 polynomial**) die Baseline, an der sich neuronale Netze messen lassen müssen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
