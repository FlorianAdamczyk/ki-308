{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 3. Regularisierte Regression: LASSO & Ridge\n",
    "\n",
    "**KI1-Projekt 308** — California Housing Datensatz\n",
    "\n",
    "**Schwerpunkt P1:** Feature-Selektion via LASSO, Ridge-Regression,\n",
    "polynomiale Feature-Transformation, Skalierungseffekte.\n",
    "\n",
    "Vorlage: HA9/10 Aufgabe 3 und HA11 Aufgabe 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Lasso, LassoCV, Ridge, RidgeCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from utils.data import load_and_clean_data, get_train_test_split\n",
    "from utils.evaluation import evaluate_model, add_result\n",
    "from utils.plotting import plot_predicted_vs_actual, plot_residuals, save_fig\n",
    "\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 3.1 Daten laden (ohne Skalierung)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_and_clean_data()\n",
    "X_train, X_test, y_train, y_test, feature_names = get_train_test_split(df)\n",
    "print(f\"Features: {feature_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 3.2 LassoCV — Feature-Selektion ohne Skalierung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimales alpha: {lasso_cv.alpha_:.6f}\\n\")\n",
    "\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Koeffizient': lasso_cv.coef_\n",
    "})\n",
    "print(\"LASSO Koeffizienten:\")\n",
    "print(coef_df.to_string(index=False))\n",
    "\n",
    "selected_features = coef_df[coef_df['Koeffizient'] != 0]['Feature'].tolist()\n",
    "print(f\"\\nSelektierte Features ({len(selected_features)}/{len(feature_names)}): {selected_features}\")\n",
    "\n",
    "result_lasso = evaluate_model(lasso_cv, X_train, X_test, y_train, y_test, \"LassoCV (ohne Skalierung)\")\n",
    "add_result(result_lasso)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3.3 Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = RidgeCV(alphas=np.logspace(-3, 3, 100), cv=5)\n",
    "ridge_cv.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Optimales alpha: {ridge_cv.alpha_:.6f}\\n\")\n",
    "\n",
    "result_ridge = evaluate_model(ridge_cv, X_train, X_test, y_train, y_test, \"RidgeCV (ohne Skalierung)\")\n",
    "add_result(result_ridge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 3.4 Mit MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mm, X_test_mm, y_train_mm, y_test_mm, scaler_mm, fn = get_train_test_split(df, scaler='minmax')\n",
    "\n",
    "lasso_cv_mm = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv_mm.fit(X_train_mm, y_train_mm)\n",
    "\n",
    "print(f\"Optimales alpha (MinMax): {lasso_cv_mm.alpha_:.6f}\")\n",
    "print(\"\\nKoeffizienten:\")\n",
    "for name, coef in zip(fn, lasso_cv_mm.coef_):\n",
    "    print(f\"  {name:15s}: {coef:.6f}\")\n",
    "\n",
    "result_lasso_mm = evaluate_model(lasso_cv_mm, X_train_mm, X_test_mm, y_train_mm, y_test_mm, \"LassoCV (MinMax)\")\n",
    "add_result(result_lasso_mm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 3.5 Mit StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss, X_test_ss, y_train_ss, y_test_ss, scaler_ss, fn = get_train_test_split(df, scaler='standard')\n",
    "\n",
    "lasso_cv_ss = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_cv_ss.fit(X_train_ss, y_train_ss)\n",
    "\n",
    "print(f\"Optimales alpha (Standard): {lasso_cv_ss.alpha_:.6f}\")\n",
    "print(\"\\nKoeffizienten:\")\n",
    "for name, coef in zip(fn, lasso_cv_ss.coef_):\n",
    "    print(f\"  {name:15s}: {coef:.6f}\")\n",
    "\n",
    "result_lasso_ss = evaluate_model(lasso_cv_ss, X_train_ss, X_test_ss, y_train_ss, y_test_ss, \"LassoCV (Standard)\")\n",
    "add_result(result_lasso_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 3.6 Polynomiale Feature-Transformation + LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polynomiale Features (Grad 2) auf skalierten Daten\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_ss)\n",
    "X_test_poly = poly.transform(X_test_ss)\n",
    "\n",
    "print(f\"Originale Features: {X_train_ss.shape[1]}\")\n",
    "print(f\"Polynomiale Features: {X_train_poly.shape[1]}\")\n",
    "\n",
    "lasso_poly = LassoCV(cv=5, random_state=42, max_iter=10000)\n",
    "lasso_poly.fit(X_train_poly, y_train_ss)\n",
    "\n",
    "result_lasso_poly = evaluate_model(\n",
    "    lasso_poly, X_train_poly, X_test_poly, y_train_ss, y_test_ss,\n",
    "    \"LassoCV (Poly Grad 2 + Standard)\"\n",
    ")\n",
    "add_result(result_lasso_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleichsplot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "plot_predicted_vs_actual(\n",
    "    y_test_ss, lasso_cv_ss.predict(X_test_ss),\n",
    "    title=\"LassoCV (Standard)\", ax=axes[0]\n",
    ")\n",
    "plot_predicted_vs_actual(\n",
    "    y_test_ss, lasso_poly.predict(X_test_poly),\n",
    "    title=\"LassoCV (Poly+Standard)\", ax=axes[1]\n",
    ")\n",
    "\n",
    "fig.suptitle(\"Vergleich: Linear vs. Polynomial\", fontsize=14)\n",
    "fig.tight_layout()\n",
    "save_fig(fig, \"lasso_comparison\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## 3.7 Zusammenfassung\n",
    "\n",
    "| Erkenntnis | Detail |\n",
    "|-----------|--------|\n",
    "| Feature-Selektion via LASSO | Identifiziert die wichtigsten Features |\n",
    "| Skalierung | Nötig für polynomiale Transformation |\n",
    "| Ridge vs. LASSO | Ridge behält alle Features, LASSO selektiert |\n",
    "| Polynomiale Features | Leichte Verbesserung durch Interaktionsterme |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
